# rag_agent_ui.py
# ëª©ì : ì•½í’ˆ ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ëŠ” RAG ê¸°ë°˜ Agent + Gradio UI

import os
import gradio as gr
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.vectorstores import Pinecone
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate
from langchain.schema import Document
from langchain_teddynote import logging

# 1. í™˜ê²½ë³€ìˆ˜ ë¡œë“œ ë° LangSmith ì¶”ì  ì„¤ì •
load_dotenv()
logging.langsmith("7_rag_drug_chat_ui")

# 2. í™˜ê²½ë³€ìˆ˜ ì„¤ì •
PINECONE_API_KEY = os.getenv("PINECONE_API_KEY")
PINECONE_INDEX_NAME = os.getenv("PINECONE_INDEX_NAME", "medical-db")
NAMESPACE = "drug-rag-namespace"

# 3. ì„ë² ë”© ëª¨ë¸ ë° ë²¡í„°ìŠ¤í† ì–´ ì´ˆê¸°í™”
embeddings = OpenAIEmbeddings(model="text-embedding-3-large")
vectorstore = Pinecone.from_existing_index(
    index_name=PINECONE_INDEX_NAME,
    embedding=embeddings,
    namespace=NAMESPACE
)

# 4. LLM ëª¨ë¸ ì„¤ì •
llm = ChatOpenAI(
    model="gpt-4-turbo-preview",
    temperature=0.7
)

# 5. í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
prompt_template = """
ë‹¤ìŒì€ ì•½í’ˆ ì •ë³´ì— ëŒ€í•œ ì§ˆë¬¸ê³¼ ë‹µë³€ í˜•ì‹ì…ë‹ˆë‹¤:

ì§ˆë¬¸: {question}

ë‹µë³€: ë‹¤ìŒ ì•½í’ˆ ì •ë³´ë¥¼ ì°¸ê³ í•˜ì—¬ ë‹µë³€í•´ì£¼ì„¸ìš”:
{context}

ë‹µë³€ í˜•ì‹:
1. ì•½í’ˆëª…: [ì•½í’ˆëª…]
2. íš¨ëŠ¥/íš¨ê³¼: [íš¨ëŠ¥/íš¨ê³¼]
3. ì‚¬ìš©ë²•: [ì‚¬ìš©ë²•]
4. ì£¼ì˜ì‚¬í•­: [ì£¼ì˜ì‚¬í•­]
5. ë¶€ì‘ìš©: [ë¶€ì‘ìš©]
6. ìƒí˜¸ì‘ìš©: [ìƒí˜¸ì‘ìš©]

ë‹µë³€:"""

PROMPT = PromptTemplate(
    template=prompt_template,
    input_variables=["context", "question"]
)

# 6. RAG ì²´ì¸ êµ¬ì„±
chain = RetrievalQA.from_chain_type(
    llm=llm,
    chain_type="stuff",
    retriever=vectorstore.as_retriever(search_kwargs={"k": 3}),
    chain_type_kwargs={"prompt": PROMPT},
    return_source_documents=True
)

# 7. ì§ˆì˜ í•¨ìˆ˜ ì •ì˜
def query_drug_info(query: str) -> str:
    try:
        result = chain.invoke({"query": query})
        answer = result["result"]
        sources = result["source_documents"]

        source_info = "\n\nğŸ“š ì°¸ê³ í•œ ì•½í’ˆ ì •ë³´:\n"
        for i, doc in enumerate(sources, 1):
            source_info += f"{i}. {doc.metadata.get('itemName', 'ì•Œ ìˆ˜ ì—†ìŒ')}\n"

        return answer + source_info
    except Exception as e:
        return f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"

# 8. Gradio UI ì •ì˜
def build_ui():
    with gr.Blocks(title="ì•½í’ˆ ê²€ìƒ‰ ì—ì´ì „íŠ¸") as demo:
        gr.Markdown("""# ğŸ’Š ì•½í’ˆ ì •ë³´ ê²€ìƒ‰ ì—ì´ì „íŠ¸
        GPT-4 + Pinecone ê¸°ë°˜ìœ¼ë¡œ ì•½í’ˆ ì •ë³´ë¥¼ ê²€ìƒ‰í•´ë“œë¦½ë‹ˆë‹¤.
        """)
        query = gr.Textbox(
            label="ì§ˆë¬¸",
            placeholder="ì˜ˆ: ì•„ìŠ¤í”¼ë¦° íš¨ëŠ¥ê³¼ ë¶€ì‘ìš© ì•Œë ¤ì¤˜"
        )
        output = gr.Textbox(label="ë‹µë³€")

        query.submit(fn=query_drug_info, inputs=query, outputs=output)

    return demo

# 9. ì‹¤í–‰
if __name__ == "__main__":
    print("ğŸš€ ì•½í’ˆ ê²€ìƒ‰ ì—ì´ì „íŠ¸ UI ì‹¤í–‰ ì¤‘...")
    ui = build_ui()
    ui.launch(share=True)