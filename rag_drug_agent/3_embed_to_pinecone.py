# 3_embed_to_pinecone.py (rag_drug_agentìš©)
# ëª©ì : drug_chunks.csvë¥¼ ê¸°ë°˜ìœ¼ë¡œ Pineconeì— ë²¡í„° ì—…ë¡œë“œ

import os
import pandas as pd
from dotenv import load_dotenv
from langchain.docstore.document import Document
from langchain_openai import OpenAIEmbeddings
from pinecone import Pinecone, ServerlessSpec
from tqdm import tqdm
import concurrent.futures
from typing import List, Dict, Any
# LangSmith ì¶”ì  ì„¤ì •
from langchain_teddynote import logging
logging.langsmith("3_embed_to_pinecone")
# 1. í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

PINECONE_API_KEY = os.getenv("PINECONE_API_KEY")
PINECONE_INDEX_NAME = os.getenv("PINECONE_INDEX_NAME", "medical-db")
PINECONE_REGION = os.getenv("PINECONE_REGION", "us-east-1")
NAMESPACE = "drug-rag-namespace"

# 2. ë°ì´í„° ë¡œë“œ ë° Document ë³€í™˜
def load_documents(filepath="data/drug_chunks.csv"):
    df = pd.read_csv(filepath)
    df.fillna("", inplace=True)
    documents = [
        Document(
            page_content=row["chunk"],
            metadata={"itemName": row["itemName"]}
        )
        for _, row in df.iterrows()
    ]
    return documents

# 3. Pinecone ì¸ë±ìŠ¤ ìƒì„± ë˜ëŠ” ì—°ê²°
def get_or_create_index():
    pc = Pinecone(api_key=PINECONE_API_KEY)

    if PINECONE_INDEX_NAME not in pc.list_indexes().names():
        pc.create_index(
            name=PINECONE_INDEX_NAME,
            dimension=3072,
            metric="dotproduct",
            spec=ServerlessSpec(cloud="aws", region=PINECONE_REGION)
        )
        print(f"âœ… Pinecone ì¸ë±ìŠ¤ ìƒì„± ì™„ë£Œ: {PINECONE_INDEX_NAME}")

    return pc.Index(PINECONE_INDEX_NAME)

# 4. ë°°ì¹˜ ì²˜ë¦¬ í•¨ìˆ˜
def process_batch(batch: List[Document], embeddings: OpenAIEmbeddings, index: Any):
    texts = [doc.page_content for doc in batch]
    metadatas = [doc.metadata for doc in batch]

    vectors = embeddings.embed_documents(texts)

    index.upsert(
        vectors=[
            (f"doc_{i}", vector, metadata)
            for i, (vector, metadata) in enumerate(zip(vectors, metadatas))
        ],
        namespace=NAMESPACE
    )

# 5. ë©”ì¸ ì‹¤í–‰
if __name__ == "__main__":
    print("ğŸš€ ì•½í’ˆ ì •ë³´ ë²¡í„° ì €ì¥ ì‹œì‘...")

    try:
        print("ğŸ“„ ë¬¸ì„œ ë¡œë“œ ì¤‘...")
        documents = load_documents()

        print("ğŸ“Œ Pinecone ì¸ë±ìŠ¤ ì¤€ë¹„ ì¤‘...")
        index = get_or_create_index()

        print("ğŸ”— ì„ë² ë”© ëª¨ë¸ ì¤€ë¹„ ì¤‘...")
        embeddings = OpenAIEmbeddings(model="text-embedding-3-large")

        BATCH_SIZE = 64
        batches = [documents[i:i + BATCH_SIZE] for i in range(0, len(documents), BATCH_SIZE)]

        print("ğŸš€ ë²¡í„° ì—…ë¡œë“œ ì¤‘...")
        with concurrent.futures.ThreadPoolExecutor(max_workers=8) as executor:
            futures = [
                executor.submit(process_batch, batch, embeddings, index)
                for batch in batches
            ]

            for _ in tqdm(concurrent.futures.as_completed(futures), total=len(futures)):
                pass

        print("âœ… ë²¡í„° ì €ì¥ ì™„ë£Œ: Pinecone")

    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")