# ëª©ì : Streamlit UIë¡œ ì•½í’ˆ RAG ì—ì´ì „íŠ¸ ì œê³µ + í”¼ë“œë°± ì €ì¥

import os
import streamlit as st
import csv
from datetime import datetime
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.vectorstores import Pinecone
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate
from langchain.schema import Document
from langchain_teddynote import logging
logging.langsmith("8_rag_agent_streamlit")

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# ì„¤ì • ê°’ ë¡œë”©
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
PINECONE_API_KEY = os.getenv("PINECONE_API_KEY")
PINECONE_INDEX_NAME = os.getenv("PINECONE_INDEX_NAME", "medical-db")
NAMESPACE = "drug-rag-namespace"

# ì„ë² ë”© ë° ë²¡í„°ìŠ¤í† ì–´ ì´ˆê¸°í™”
embeddings = OpenAIEmbeddings(model="text-embedding-3-large")
vectorstore = Pinecone.from_existing_index(
    index_name=PINECONE_INDEX_NAME,
    embedding=embeddings,
    namespace=NAMESPACE
)

# LLM
llm = ChatOpenAI(model="gpt-4-turbo-preview", temperature=0.7)

# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
template = """
ë‹¤ìŒì€ ì•½í’ˆ ì •ë³´ì— ëŒ€í•œ ì§ˆë¬¸ê³¼ ë‹µë³€ í˜•ì‹ì…ë‹ˆë‹¤:

ì§ˆë¬¸: {question}

ë‹µë³€: ë‹¤ìŒ ì•½í’ˆ ì •ë³´ë¥¼ ì°¸ê³ í•˜ì—¬ ë‹µë³€í•´ì£¼ì„¸ìš”:
{context}

ë‹µë³€ í˜•ì‹:
1. ì•½í’ˆëª…: [ì•½í’ˆëª…]
2. íš¨ëŠ¥/íš¨ê³¼: [íš¨ëŠ¥/íš¨ê³¼]
3. ì‚¬ìš©ë²•: [ì‚¬ìš©ë²•]
4. ì£¼ì˜ì‚¬í•­: [ì£¼ì˜ì‚¬í•­]
5. ë¶€ì‘ìš©: [ë¶€ì‘ìš©]
6. ìƒí˜¸ì‘ìš©: [ìƒí˜¸ì‘ìš©]

ë‹µë³€:
"""
PROMPT = PromptTemplate(template=template, input_variables=["context", "question"])

# RAG ì²´ì¸
chain = RetrievalQA.from_chain_type(
    llm=llm,
    chain_type="stuff",
    retriever=vectorstore.as_retriever(search_kwargs={"k": 3}),
    chain_type_kwargs={"prompt": PROMPT},
    return_source_documents=True
)

# ì§ˆë¬¸-ì‘ë‹µ-ì¶œì²˜ ê¸°ë¡ ì €ì¥
LOG_PATH = "logs/streamlit_feedback_log.csv"
os.makedirs("logs", exist_ok=True)

def save_feedback_log(query, answer, sources, feedback):
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    source_names = ", ".join([doc.metadata.get("itemName", "N/A") for doc in sources])
    with open(LOG_PATH, mode="a", encoding="utf-8", newline="") as f:
        writer = csv.writer(f)
        writer.writerow([timestamp, query, answer, source_names, feedback])

# Streamlit UI
st.set_page_config(page_title="ğŸ’Š ì•½í’ˆ RAG ì±—ë´‡", layout="centered")
st.title("ğŸ’Š ì•½í’ˆ ì •ë³´ ê²€ìƒ‰ ì—ì´ì „íŠ¸")
st.markdown("GPT-4 + Pinecone ê¸°ë°˜ìœ¼ë¡œ ì•½í’ˆ ì •ë³´ë¥¼ ê²€ìƒ‰í•´ë“œë¦½ë‹ˆë‹¤.")

query = st.text_input("ê¶ê¸ˆí•œ ì ì„ ì…ë ¥í•˜ì„¸ìš”:", placeholder="ì˜ˆ: íƒ€ì´ë ˆë†€ ë¶€ì‘ìš©ì€?")

if query:
    with st.spinner("ë‹µë³€ ìƒì„± ì¤‘..."):
        result = chain.invoke({"query": query})
        answer = result["result"]
        sources = result["source_documents"]

        source_list = "\n".join([f"- {doc.metadata.get('itemName', 'ì•Œ ìˆ˜ ì—†ìŒ')}" for doc in sources])
        st.markdown("#### ğŸ“Œ ë‹µë³€")
        st.markdown(answer)
        st.markdown("#### ğŸ“š ì°¸ê³ í•œ ì•½í’ˆ ì •ë³´")
        st.code(source_list, language="")

        # í”¼ë“œë°± ë²„íŠ¼
        col1, col2 = st.columns(2)
        with col1:
            if st.button("ğŸ‘ ë„ì›€ì´ ë˜ì—ˆì–´ìš”"):
                save_feedback_log(query, answer, sources, "positive")
                st.success("í”¼ë“œë°± ê°ì‚¬í•©ë‹ˆë‹¤!")
        with col2:
            if st.button("ğŸ‘ ë¶€ì¡±í–ˆì–´ìš”"):
                save_feedback_log(query, answer, sources, "negative")
                st.warning("ë” ë‚˜ì€ ë‹µë³€ì„ ìœ„í•´ ë…¸ë ¥í• ê²Œìš”!")