import os
import streamlit as st
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.vectorstores import Pinecone
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate

# 0. ì´ˆê¸° ì„¤ì • ë° í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
PINECONE_API_KEY = os.getenv("PINECONE_API_KEY")
PINECONE_INDEX_NAME = os.getenv("PINECONE_INDEX_NAME", "medical-db")
NAMESPACE = "drug-rag-namespace"

# 1. ë²¡í„°ìŠ¤í† ì–´ ì´ˆê¸°í™”
embeddings = OpenAIEmbeddings(model="text-embedding-3-large")
vectorstore = Pinecone.from_existing_index(
    index_name=PINECONE_INDEX_NAME,
    embedding=embeddings,
    namespace=NAMESPACE
)
retriever = vectorstore.as_retriever(search_kwargs={"k": 3})

# 2. LLM ë° í”„ë¡¬í”„íŠ¸ ì„¸íŒ… (ì§ˆë¬¸ì— ë§ëŠ” ì •ë³´ë§Œ ì¶”ì¶œí•˜ê²Œ ìœ ë„)
template = """
ë„ˆëŠ” ì•½í•™ ì „ë¬¸ ìƒë‹´ ì±—ë´‡ì´ì•¼. ì•„ë˜ì˜ ì•½í’ˆ ì •ë³´ë¥¼ ì°¸ê³ í•˜ì—¬ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— **ê´€ë ¨ëœ ë‚´ìš©ë§Œ** ê³¨ë¼ì„œ ê°„ê²°í•˜ê²Œ ë‹µë³€í•´ì¤˜.

ì•½í’ˆ ì •ë³´:
{context}

ì‚¬ìš©ì ì§ˆë¬¸:
{question}

ğŸ’¬ ë‹µë³€:
- ì‚¬ìš©ìì˜ ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ì•½í’ˆ ì •ë³´ë§Œ ìš”ì•½í•´ì„œ ì•Œë ¤ì¤˜.
- ì§ˆë¬¸ê³¼ ê´€ë ¨ ì—†ëŠ” ì •ë³´ëŠ” ì¶œë ¥í•˜ì§€ ë§ˆ.
"""
PROMPT = PromptTemplate(template=template, input_variables=["context", "question"])

rag_chain = RetrievalQA.from_chain_type(
    llm=ChatOpenAI(model="gpt-4-turbo-preview", temperature=0.7),
    chain_type="stuff",
    retriever=retriever,
    chain_type_kwargs={"prompt": PROMPT},
    return_source_documents=True
)

# 3. Streamlit UI
st.set_page_config(page_title="ğŸ’Š ì•½í’ˆ ê²€ìƒ‰ ë¹„êµ", layout="centered")
st.title("ğŸ” RAG vs í‚¤ì›Œë“œ ê²€ìƒ‰ ë¹„êµ")

mode = st.sidebar.radio("ê²€ìƒ‰ ëª¨ë“œ ì„ íƒ", ["RAG ì‘ë‹µ (GPT í¬í•¨)", "í‚¤ì›Œë“œ ê¸°ë°˜ ë¬¸ì„œ ê²€ìƒ‰"])
query = st.text_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”", placeholder="ì˜ˆ: íƒ€ì´ë ˆë†€ì˜ ë¶€ì‘ìš©ì€?")

if query:
    with st.spinner("ê²€ìƒ‰ ì¤‘..."):
        if mode == "RAG ì‘ë‹µ (GPT í¬í•¨)":
            result = rag_chain.invoke({"query": query})
            st.subheader("ğŸ“Œ GPT ì‘ë‹µ")
            st.markdown(result["result"])

            st.subheader("ğŸ“š ì°¸ê³  ë¬¸ì„œ")
            for doc in result["source_documents"]:
                st.markdown(f"**{doc.metadata.get('itemName', 'ì•Œ ìˆ˜ ì—†ìŒ')}**")
                st.code(doc.page_content.strip()[:1000])

        else:
            docs = retriever.invoke(query)
            st.subheader("ğŸ“„ ìœ ì‚¬ ë¬¸ì„œ ê²°ê³¼")
            for i, doc in enumerate(docs, 1):
                st.markdown(f"### {i}. {doc.metadata.get('itemName', 'ì•Œ ìˆ˜ ì—†ìŒ')}")
                st.code(doc.page_content.strip()[:1000])
